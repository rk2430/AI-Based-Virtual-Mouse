Hand Gesture Controller using OpenCV & MediaPipe

This project enables touchless control of your computer using hand gestures captured through a webcam.
It supports controlling mouse movement, left/right click, scrolling, double click, system volume, and system brightnessâ€”all with simple intuitive gestures.

The system uses:

OpenCV â€“ camera input & frame processing

MediaPipe Hands â€“ real-time hand landmark detection

PyAutoGUI â€“ controlling mouse actions

PyCAW â€“ controlling system audio

screen_brightness_control â€“ brightness management

Mathematical gesture mapping â€“ identifying finger positions & gestures


Features
Mouse Control
Gesture	Action
âœŒï¸ V-Gesture	Enable pointer movement
âœŠ Fist	Drag (click & hold)
â˜ï¸ Index finger	Right click
ğŸ‘† Middle finger	Left click
Two-finger closed	Double Click
Scrolling
Gesture	Action
Minor-hand pinch	Scroll (vertical or horizontal)

Brightness & Volume
Gesture	Action
Major-hand pinch	Brightness / Volume control (auto-detect horizontal/vertical pinch direction)

The program automatically classifies major hand (right) and minor hand (left) using MediaPipeâ€™s handedness estimation.

Project Structure
main.py          # Main script for gesture recognition & control
README.md        # Documentation file

ğŸ› ï¸ Installation
1. Clone the Repository
git clone <your-repository-link>
cd gesture-controller

2. Install Dependencies

Make sure you have Python 3.7+.

pip install opencv-python mediapipe pyautogui comtypes pycaw screen-brightness-control


If pycaw causes issues:

pip install pycaw==20230407

â–¶ï¸ How to Run

Just run the script using Python:

python main.py


NOTE: This is not a Streamlit app.
No streamlit run command is needed.
Use: python main.py

ğŸ¯ How It Works
1. Hand Detection

The script uses MediaPipe Hands to obtain 21 landmark points per hand.

2. Gesture Encoding

Finger openness is converted into a binary number, mapped to custom gesture enums such as:

FIST, INDEX, V_GEST, PINCH_MAJOR, etc.

3. Gesture Stabilization

To avoid jitter, gestures are confirmed only after several consecutive frames match.

4. Action Execution

Based on the detected gesture:

Mouse position â†’ via pyautogui.moveTo()

Scroll actions â†’ pyautogui.scroll()

Volume â†’ via IAudioEndpointVolume

Brightness â†’ via screen_brightness_control

ğŸ“¸ Starting the Program

When main.py runs:

A webcam feed opens

Hand landmarks are drawn

Gestures are recognized in real-time

Actions are executed instantly

Press Enter (â†µ) to exit.

âš ï¸ Safety & Notes

Ensure good lighting for accurate tracking.

Keep your hand within the cameraâ€™s view.

Disable PyAutoGUI failsafe (pyautogui.FAILSAFE = False) is already handled in the scriptâ€”so be cautious when moving the cursor fast.

Works best on systems with a high-quality webcam.

ğŸ”§ Requirements

Windows OS (for PyCAW audio control)

Webcam

Python 3.7+

ğŸ“Œ Future Improvements

Add gesture customization UI

Add multi-gesture recording

Add support for Linux & macOS

Integrate AI-based gesture classification
